{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637ec8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def generate_json_from_excel(model):\n",
    "\n",
    "    # Read the .xlsx file, ensuring 'N/A' is treated as a string\n",
    "    data = pd.read_excel(\"Model \"+model+\".xlsx\", na_values=[], keep_default_na=False)\n",
    "\n",
    "    # Define the path for the output .jsonl file\n",
    "    output_path = \"Model \"+model+\"_json.jsonl\"\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(output_path, 'w') as file:\n",
    "        # Iterate over each row in the dataframe\n",
    "        for index, row in data.iterrows():\n",
    "            # Create the JSON object for each row\n",
    "            json_obj = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": row[\"system\"]},\n",
    "                    {\"role\": \"user\", \"content\": row[\"user\"]},\n",
    "                    {\"role\": \"assistant\", \"content\": row[\"assistant\"]}\n",
    "                ]\n",
    "            }\n",
    "            # Write the JSON object to the file\n",
    "            file.write(json.dumps(json_obj) + '\\n')\n",
    "\n",
    "    print(f\"Data of Model {model} has been successfully converted and saved to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def check_json(model):\n",
    "    #function provide by OpenAI\n",
    "    #we specify the data path and open the JSONL file\n",
    "\n",
    "    data_path = \"Model \"+model+\"_json.jsonl\"\n",
    "\n",
    "    # Load dataset\n",
    "    with open(data_path) as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    # We can inspect the data quickly by checking the number of examples and the first item\n",
    "\n",
    "    # Initial dataset stats\n",
    "    print(\"Num examples:\", len(dataset))\n",
    "    print(\"First example:\")\n",
    "    for message in dataset[0][\"messages\"]:\n",
    "        print(message)\n",
    "\n",
    "    # Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
    "\n",
    "    # Format error checks\n",
    "    format_errors = defaultdict(int)\n",
    "\n",
    "    for ex in dataset:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "\n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "\n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "            if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "            content = message.get(\"content\", None)\n",
    "            if not content or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "\n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "    if format_errors:\n",
    "        print(\"Found errors:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        num_error=0\n",
    "        print(\"No errors found\")\n",
    "\n",
    "    # Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
    "\n",
    "    # Token counting functions\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    # not exact!\n",
    "    # simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "    def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "        num_tokens = 0\n",
    "        for message in messages:\n",
    "            num_tokens += tokens_per_message\n",
    "            for key, value in message.items():\n",
    "                if not isinstance(value, str):\n",
    "                    print(f\"Error in message: {message}\")\n",
    "                    print(f\"Invalid value for key '{key}': {value} (type: {type(value)})\")\n",
    "                    continue\n",
    "                num_tokens += len(encoding.encode(value))\n",
    "                if key == \"name\":\n",
    "                    num_tokens += tokens_per_name\n",
    "        num_tokens += 3\n",
    "        return num_tokens\n",
    "\n",
    "    def num_assistant_tokens_from_messages(messages):\n",
    "        num_tokens = 0\n",
    "        for message in messages:\n",
    "            if message[\"role\"] == \"assistant\":\n",
    "                num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "        return num_tokens\n",
    "\n",
    "    def print_distribution(values, name):\n",
    "        print(f\"\\n#### Distribution of {name}:\")\n",
    "        print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "        print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "        print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "    # Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
    "\n",
    "    # Warnings and tokens counts\n",
    "    n_missing_system = 0\n",
    "    n_missing_user = 0\n",
    "    n_messages = []\n",
    "    convo_lens = []\n",
    "    assistant_message_lens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex[\"messages\"]\n",
    "        if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "            n_missing_system += 1\n",
    "        if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "            n_missing_user += 1\n",
    "        n_messages.append(len(messages))\n",
    "        convo_lens.append(num_tokens_from_messages(messages))\n",
    "        assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print(\"Num examples missing system message:\", n_missing_system)\n",
    "    print(\"Num examples missing user message:\", n_missing_user)\n",
    "    print_distribution(n_messages, \"num_messages_per_example\")\n",
    "    print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "    print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "    n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "    print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
    "\n",
    "    # Pricing and default n_epochs estimate\n",
    "    MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "    MIN_TARGET_EXAMPLES = 100\n",
    "    MAX_TARGET_EXAMPLES = 25000\n",
    "    TARGET_EPOCHS = 3\n",
    "    MIN_EPOCHS = 1\n",
    "    MAX_EPOCHS = 25\n",
    "\n",
    "    n_epochs = TARGET_EPOCHS\n",
    "    n_train_examples = len(dataset)\n",
    "    if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "        n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "    elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "        n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "    n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "    print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "    print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "    print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")    \n",
    "    \n",
    "    return num_error \n",
    "    \n",
    "def start_ft(model):\n",
    "    new_upload = openai.File.create(\n",
    "      file=open( \"Model \"+model+\"_json.jsonl\", \"rb\"),\n",
    "      purpose='fine-tune'\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    print(f\"Data of Model {model} has been uploaded. Please wait for 2 minutes to start the job.\")\n",
    "    print(new_upload)\n",
    "    time.sleep(120)\n",
    "\n",
    "\n",
    "    for _ in range(100):  # Max attempts\n",
    "        print(f\"Try to create fine-tuning job for Model {model}. The job ID is {new_upload.id}\")\n",
    "        try:\n",
    "            ft_model = openai.FineTuningJob.create(training_file=new_upload.id, model=\"gpt-3.5-turbo\")\n",
    "            print(\"Fine-tuning job created successfully! Please check the email for the model ID.\")\n",
    "            print(ft_model)\n",
    "            print(\"\\n\")\n",
    "            break\n",
    "        except openai.error.InvalidRequestError as e:\n",
    "            if \"still being processed\" in str(e):\n",
    "                print(\"File is still being processed. Retrying in 30 seconds...\")\n",
    "                time.sleep(30)  # Wait for 30 seconds\n",
    "            else:\n",
    "                raise e\n",
    "        except openai.error.RateLimitError as e:\n",
    "            if \"rate-limited\" in str(e):\n",
    "                if \"per day\"in str(e):\n",
    "                    print(\"12 task per day limit reached.\")\n",
    "                    time.sleep(10000)  # Wait for 90 minutes\n",
    "                print(\"Rate limit reached. Retrying in 10 minutes...\")\n",
    "                time.sleep(600)  # Wait for 10 minutes\n",
    "            else:\n",
    "                raise e\n",
    "      \n",
    "    else:\n",
    "        print(\"Max attempts reached. Fine-tuning job could not be created.\")\n",
    "    return new_upload.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f35ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "Start to process Model 1S.\n",
      "\n",
      "Data of Model 1S has been successfully converted and saved to Model 1S_json.jsonl\n",
      "Num examples: 1990\n",
      "First example:\n",
      "{'role': 'system', 'content': \"You are an AI assistant with expertise in organic chemistry. Your task is to make theoretical modifications to a given SMILES code of a MOF linker.  Your objective is introduce new functional groups or alter existing ones to the linker, then provide the correct molecular representation for the modified linker. You should never remove or modify the carboxylate groups, as they are essential to MOF linkers. The user can choose from 5 mutation actions:\\n\\n(1) Introduce or remove a methyl group from the ring.\\n(2) Introduce or remove a hydroxyl group from the ring.\\n(3) Introduce or remove an amino group from the ring.\\n(4) Introduce or remove a nitro group from the ring.\\n(5) Introduce or remove a fluoro group to the ring.\\n\\nThe user will first specify the desired mutation action, followed by 'Action: '. In the next line, the user will provide the SMILES code of the MOF linker to be mutated, starting with 'Compound: '.\\n\\nYour response should begin with 'New Compound: ', followed by the updated SMILES code. If the requested mutation isn't chemically feasible, due to bonding constraints or if the given structure isn't compatible with the mutation (e.g., it lacks a ring or a suitable substitution site), you should respond with 'New Compound: Invalid'.\"}\n",
      "{'role': 'user', 'content': 'Action: Introduce or remove a methyl group from the ring.\\nCompound: OC(=O)c1nccnc1C(O)=O'}\n",
      "{'role': 'assistant', 'content': 'New Compound: Cc1cnc(C(O)=O)c(n1)C(O)=O'}\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 319, 467\n",
      "mean / median: 382.95979899497485, 382.0\n",
      "p5 / p95: 345.0, 425.10000000000014\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 4, 86\n",
      "mean / median: 40.70301507537688, 41.0\n",
      "p5 / p95: 21.0, 64.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~762090 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~2286270 tokens\n",
      "\n",
      "\n",
      "Data of Model 1S has been uploaded. Please wait for 2 minutes to start the job.\n",
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-1VhFgIzNKMZcKcQpbb4jT1VO\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 3162899,\n",
      "  \"created_at\": 1694110618,\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "Try to create fine-tuning job for Model 1S. The job ID is file-1VhFgIzNKMZcKcQpbb4jT1VO\n",
      "Rate limit reached. Retrying in 10 minutes...\n"
     ]
    }
   ],
   "source": [
    "method_type = \"S\"\n",
    "\n",
    "for i in range(1, 7):  # Loop from Model 1 to Model 6\n",
    "    model = str(i) + method_type\n",
    "    \n",
    "    print(\"\\n++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Start to process Model {model}.\\n\")\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    generate_json_from_excel(model)\n",
    "    check_json(model)\n",
    "    start_ft(model)\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    \n",
    "    print(f\"Finish Model {model}.\\n\")\n",
    "    print(f\"Model {model} took {elapsed_time:.2f} seconds to process.\")\n",
    "    print(\"\\n++++++++++++++++++++++++++++++++++++++++++++\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "606802c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "Start to process Model 3R.\n",
      "\n",
      "Data of Model 3R has been successfully converted and saved to Model 3R_json.jsonl\n",
      "Num examples: 700\n",
      "First example:\n",
      "{'role': 'system', 'content': \"You are an AI assistant with expertise in organic chemistry. Your task is to make theoretical \\nmodifications to a given IUPAC name of a MOF linker.  Your objective is to swap out atoms in the linker with \\ndifferent heteroatoms (e.g., replace a carbon atom with a nitrogen or sulfur atom), while adhering to general \\nchemical rules and bonding constraints, such as ensuring ring stability and proper valence for atoms, then provide \\nthe correct IUPAC name for the modified linker. The user can choose from three mutation actions:\\n\\n(1) Replace a carbon atom in the ring with nitrogen, or vice versa.\\n(2) Replace a carbon atom in the ring with oxygen, or vice versa.\\n(3) Replace a carbon atom in the ring with sulfur, or vice versa.\\n\\nThe user will first specify the desired mutation action, followed by 'Action: '. In the next line, the user will \\nprovide the IUPAC name of the MOF linker to be mutated, starting with 'Compound: '.\\n\\nYour response should begin with 'New Compound: ', followed by the updated IUPAC name. If the requested mutation \\nisn't chemically feasible, due to bonding constraints or if the given structure isn't compatible with the mutation \\n(e.g., it lacks a ring or a suitable substitution site), you should respond with 'New Compound: Invalid'.\"}\n",
      "{'role': 'user', 'content': 'Action: (1) Replace a carbon atom in the ring with nitrogen, or vice versa.\\nCompound: Pyrazine-2,3-dicarboxylic acid'}\n",
      "{'role': 'assistant', 'content': 'New Compound: 1,2,4-Triazine-5,6-dicarboxylic acid'}\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 325, 527\n",
      "mean / median: 369.6642857142857, 363.0\n",
      "p5 / p95: 336.0, 408.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 4, 114\n",
      "mean / median: 24.527142857142856, 23.0\n",
      "p5 / p95: 4.0, 50.10000000000002\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~258765 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~776295 tokens\n",
      "\n",
      "\n",
      "Data of Model 3R has been uploaded. Please wait for 2 minutes to start the job.\n",
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-wCTsmgxhBEMvVc68ys1ZFbNU\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 1122622,\n",
      "  \"created_at\": 1694047896,\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "Try to create fine-tuning job for Model 3R. The job ID is file-wCTsmgxhBEMvVc68ys1ZFbNU\n",
      "Fine-tuning job created successfully! Please check the email for the model ID.\n",
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-DpmKa4qheJULDUXhQKPWD6n4\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created_at\": 1694048017,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"created\",\n",
      "  \"validation_file\": null,\n",
      "  \"training_file\": \"file-wCTsmgxhBEMvVc68ys1ZFbNU\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"trained_tokens\": null\n",
      "}\n",
      "\n",
      "\n",
      "Finish Model 3R.\n",
      "\n",
      "Model 3R took 122.62 seconds to process.\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "method_type = \"R\"\n",
    "\n",
    "for i in range(3, 4):  # Loop from Model 3 ONLY\n",
    "    model = str(i) + method_type\n",
    "    \n",
    "    print(\"\\n++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Start to process Model {model}.\\n\")\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    generate_json_from_excel(model)\n",
    "    check_json(model)\n",
    "    start_ft(model)\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    \n",
    "    print(f\"Finish Model {model}.\\n\")\n",
    "    print(f\"Model {model} took {elapsed_time:.2f} seconds to process.\")\n",
    "    print(\"\\n++++++++++++++++++++++++++++++++++++++++++++\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce615f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x1a60209aef0> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-mx1mi1Xy1dSFNzhG6a6A6bwG\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693988356,\n",
       "      \"finished_at\": 1693993551,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vjOau5j\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-rrEKTbx2eiy9NEyNRmNSjBdA\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-cjNCYYuUURIuVBw10TPrXSiI\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1081977\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-hSWlQC3UhhVv6LQRKRMclxE8\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693982832,\n",
       "      \"finished_at\": 1693988347,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vi2eO10\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-uJ2FCfDPY15jz2Mno8qrKyNI\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-0xUSYww1c91psU0YVOQA8YFD\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1800936\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-N17PBSmt7EcsNoDWZUbJFDEq\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693977301,\n",
       "      \"finished_at\": 1693982440,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vgVMad5\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-uTB2u01ih5HzDEfXWcZ1rDSS\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-s7vLkku2qYx4SK994eoxoflR\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1083690\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-41YdkyNKhz3uASjjHXVU0v5n\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693974176,\n",
       "      \"finished_at\": 1693976731,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vf1I6Fe\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-Bt6F8aZOyD4XkCZSzrEdBfhQ\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-hoiOMqFFLmGFNWvuBNyKUJJv\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 396312\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-ipo0o5bJR5Fj5IOw5jLcwYqH\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693969252,\n",
       "      \"finished_at\": 1693973880,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7veHJ0eR\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-FIgfFyyMfl0mDSopdqYnb5WW\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-M3byI6RgutSXtEWMyPsItf4a\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1231323\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-ut8cF4MaDjwjHEU5WlJKpU55\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693965527,\n",
       "      \"finished_at\": 1693969250,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vd4eEZu\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-gwkdU9YMaSAgHkfQLtQVLUvO\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-j6ioS2MmGEA0kpSeItCjRXKI\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 778227\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-lxxInWFkLcJdIPMjvmtJNsAu\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693950650,\n",
       "      \"finished_at\": 1693953375,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vYwZXQf\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-lshnhsjKInvXjrGzQi5Z58n6\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-do6goosgeAjLPXtSWUsSLO6R\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1815354\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-heolftniygY17Vv2laLQEPi8\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693945093,\n",
       "      \"finished_at\": 1693950571,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vYDMKKK\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-zkJoyNFg65GmV5lPANZunMft\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-9xpvCAyFPHklASOVqvLxxWmq\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1815354\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-3cbkH6uk3yfDxedo9YmYJ4XI\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693913630,\n",
       "      \"finished_at\": 1693918755,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vPwCDst\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-1uhSVW4B9rs6TTRSkwtoMcmx\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-5sAbUjON0A16PyV2a79Hsz84\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1092246\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-NlTRB384Mk7dWwdaUxfgkVKl\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693909930,\n",
       "      \"finished_at\": 1693913318,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vOWVVCU\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-PfRXrujwLx9REdrIlu1HeaQF\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-6qfCpdHNIabXjIC0aT6Leycp\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1092738\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-xi9CYNSkiHBGS0URnsdslcpD\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693906836,\n",
       "      \"finished_at\": 1693909459,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vNWFy9Q\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-XxWC07HexkhBmvaFsy0gXNb8\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-6VhXQ9WsJqLefiD3gNjfUips\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 777792\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-GYOttdcGJteVYG6o2ubg4qvc\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693904342,\n",
       "      \"finished_at\": 1693906601,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vMmBvdX\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-FMHG5D8MYTNcUfv76xF56OA6\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-GJq98FTfjp7OXX97MSCkZ2OX\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 530097\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-CoNc2rJNiw9OVzyfPuXUFEkF\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693901849,\n",
       "      \"finished_at\": 1693904055,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vM756fz\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-kOErJg9BH2oZNCVUK5yXJTbi\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-GWPbCU2YwhU77BzpHXBp1sMK\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 396312\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-dOTLRh1DrVahVluoyvii2vrg\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693896355,\n",
       "      \"finished_at\": 1693900379,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vL9nOL4\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-tI9741FFUPnQ7DyUDbr85C3N\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-6ShKdZ7f6gBbew9qHnfeOfrA\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1231323\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-Igafxg659QcyqNfcfiw9TGcU\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693892030,\n",
       "      \"finished_at\": 1693896012,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vK1NyUQ\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-RXbMP7hjfP33LYRIjjJQbivi\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-LlTTo7Yr3p770K6XBTAPJ5c8\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 778227\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-qjK0qKMFgcVY6FUGT7Kk8REL\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693887427,\n",
       "      \"finished_at\": 1693891371,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vIoVeMj\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-EnNbioLTs4fCg70V125bWobg\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-8Amcky0uX2ixDBFChRUW9h3H\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 777795\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-IOQuuXPnvtKx3qSZfQaK6H8C\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693882301,\n",
       "      \"finished_at\": 1693884347,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vGzFO3v\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-aV4TSF9Y5vbHGEqY82oLORmW\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-8YVXFN4WgI2WhW9Vd5XmSxPa\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 396312\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-YmKgDiok8B52oopPAlJkO5S9\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693878683,\n",
       "      \"finished_at\": 1693880455,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vFyS3MA\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-i9Cj3l9ZsXimxAYizGcJK9T9\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-MK5CPZYdDpSVB12mhM5RQZgW\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 377073\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-P4RIqXxeHAYd6KeCes0BWCL5\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693876189,\n",
       "      \"finished_at\": 1693878400,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vFRIMeG\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-cDuR1w9juG58FJkGFhTmLV3E\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-vcm4DjhmMonZaaT8tdK9UmJE\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 530097\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-hzwx1ZmCAsvfp1M8srMGXkhr\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693871894,\n",
       "      \"finished_at\": 1693875866,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7vEmRcxS\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-zmqaMK4vUj1B2zsec6r3o3aW\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-zBybtazv0exosiYtL8NxDOuO\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1231323\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-4vEC3icRdKtlSgevwLzVb1jd\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693820144,\n",
       "      \"finished_at\": 1693822368,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7v0rb5G8\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-Sl3rGKF4NreUNxAxAnzjqVhb\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-ET1ExC63eQqVYJFItnDawbb2\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 381045\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-nvUG4l7RMcfJzjKJ4YjCKYOn\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693816451,\n",
       "      \"finished_at\": 1693818522,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uzrXrgV\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-GAXT7nGaFWN43Xi2Woh4Eljr\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-sPho85zjAEyEqu5tBSniYqUv\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 420141\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-uZNeLYj5GtI91Q6LBne1dXzO\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693814558,\n",
       "      \"finished_at\": 1693816272,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uzHFjrG\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-dLADI3Y5psgevqhXzg05QNKI\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-enafUwEwYbtG9Cx1fOE2HI64\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 376701\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-z2Zqn4jZP9jlJLdlFZJJjSxe\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693809065,\n",
       "      \"finished_at\": 1693813653,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uyb0VuL\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-NxwZYmZMdk52FbQbiF7G0waW\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-PlYjhux1MwA8Z6j7sBiByB0Q\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 862827\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-YQ6XCQXb88QJu0wdZKxIpi4U\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693807172,\n",
       "      \"finished_at\": 1693809046,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uxOgd8G\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-82G4oewvvXR7O3RsOplzLUKv\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-e0FGLrfdjs20OXQ4UlD9p4tY\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 778227\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-RMdcjKU08UHT5IHeylXklcUL\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693695867,\n",
       "      \"finished_at\": 1693698565,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uUeknd5\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-kMpRfoFDDHJZpexjOxjkORWM\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-05shLW9AxgoGQ0GluXfgmxjf\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 350007\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-bKPOlWAgGlFmkBql4LHgSOKF\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693693974,\n",
       "      \"finished_at\": 1693695339,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uToiFyg\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-Jg941QGEjWTa5MESnRVnOZdy\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-vT9wyuvo5LAABWDP7CfiVgKz\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 503730\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-vThawF7Bv3jWvdfKF6yA46bN\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693690279,\n",
       "      \"finished_at\": 1693692457,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uT4Fjh7\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-KTi855FFJedzi4HN04Epmcrc\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-2REjuowHThyLEs8AK0AqRF1K\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 370248\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-f4gL7ZMBNpprsJJiROdDzJ5x\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693684786,\n",
       "      \"finished_at\": 1693689519,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uSIqs0O\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-x6dUUFBXLTcjt2gEAcK73i1W\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-iAjVeziOUDQQu6yfPIAtNkUT\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 1179732\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-hNrpDGtJf1DcsBv753wVjYIz\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693678589,\n",
       "      \"finished_at\": 1693683046,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:uc-berkeley::7uQcRdX5\",\n",
       "      \"organization_id\": \"org-vVj7NX8f155Kazao4Phi3tol\",\n",
       "      \"result_files\": [\n",
       "        \"file-EEMx2SaeWcau54UXm1YqUtzD\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-kKtaI46P2evonGCVS9h2DqZn\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 727131\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": true\n",
       "}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "openai.FineTuningJob.list(limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ece184be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vYwZXQf\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vYDMKKK\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vPwCDst\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vOWVVCU\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vNWFy9Q\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vMmBvdX\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vM756fz\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vL9nOL4\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vK1NyUQ\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vIoVeMj\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vGzFO3v\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vFyS3MA\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vFRIMeG\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7vEmRcxS\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7v0rb5G8\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uzrXrgV\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uzHFjrG\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uyb0VuL\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uxOgd8G\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uUeknd5\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uToiFyg\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uT4Fjh7\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uSIqs0O\")\n",
    "#openai.Model.delete(\"ft:gpt-3.5-turbo-0613:uc-berkeley::7uQcRdX5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3564bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55e2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44f259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9728b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75719b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5804c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40497115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1c453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305f79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f270a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c081a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a6801ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"THIOPHENE-2,4-DICARBOXYLIC ACID\"\n",
      "}\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"thiophene-2,3-dicarboxylic acid\"\n",
      "}\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"N/A\"\n",
      "}\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"4-(5-carboxyfuran-2-yl)furan-2-carboxylic acid\"\n",
      "}\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"N/A\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_messages = [\n",
    "    \"THIOPHENE-2,5-DICARBOXYLIC ACID\",\n",
    "    \"thiophene-2,4-dicarboxylic acid\",\n",
    "    \"ethyl 5-formylthiophene-3-carboxylate\",\n",
    "    \"5-(5-carboxyfuran-2-yl)furan-2-carboxylic acid\",\n",
    "    \"benzene\"\n",
    "]\n",
    "\n",
    "system_message = \"\"\" You are an AI assistant with expertise in organic chemistry. Your task is to make theoretical modifications to a given IUPAC name of a MOF linker. Your objective is to change the position of coordination sites, such as COOH, within aromatic or non-aromatic rings including 5-membered, 6-membered, 7-membered, and fused rings. Note that the changes can not result in invaild structures or violating any rules in chemical bonding. If no valid structures can be generated by the action or the input structure does not meet the requirement to perform the action, please answer with \"N/A\". The user will give you the IUPAC name of the linker to be modified.\n",
    "\n",
    "You should first shift the position of COOH within any ring type to another position on the same ring, and then answer with the IUPAC name of the resulting compound.  \"\"\"\n",
    "\n",
    "for user_message in user_messages:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"ft:gpt-3.5-turbo-0613:uc-berkeley::7u4Ni1Wl\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18560009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model 1R\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "user_messages = [\n",
    "    \"OC(=O)COCCOCCOCCOCCOCC(O)=O\",\n",
    "    \"OC(=O)c1cccc2c(cccc12)C(O)=O\",\n",
    "    \"OC(=O)Cc1ccc(cc1)c2ccc(CC(O)=O)cc2\",\n",
    "    \"Cc1[nH]nc(C)c1c2cc(cc(c2)C(O)=O)C(O)=O\",\n",
    "    \"OC(=O)c1cc(F)cc(c1)C(O)=O\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"You are an AI assistant with expertise in organic chemistry. Your task is to make theoretical \n",
    "modifications to a given SMILES code of a MOF linker.  Your objective is to swap out atoms in the linker with \n",
    "different heteroatoms (e.g., replace a carbon atom with a nitrogen or sulfur atom), while adhering to general \n",
    "chemical rules and bonding constraints, such as ensuring ring stability and proper valence for atoms, then provide \n",
    "the correct SMILES code for the modified linker. The user can choose from three mutation actions:\n",
    "\n",
    "(1) Replace a carbon atom in the ring with nitrogen, or vice versa.\n",
    "(2) Replace a carbon atom in the ring with oxygen, or vice versa.\n",
    "(3) Replace a carbon atom in the ring with sulfur, or vice versa.\n",
    "\n",
    "The user will first specify the desired mutation action, followed by 'Action: '. In the next line, the user will \n",
    "provide the SMILES code of the MOF linker to be mutated, starting with 'Compound: '.\n",
    "\n",
    "Your response should begin with 'New Compound: ', followed by the updated SMILES code. If the requested mutation \n",
    "isn't chemically feasible, due to bonding constraints or if the given structure isn't compatible with the mutation \n",
    "(e.g., it lacks a ring or a suitable substitution site), you should respond with 'New Compound: Invalid'.\"\"\"\n",
    "\n",
    "for user_message in user_messages:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"ft:gpt-3.5-turbo-0613:uc-berkeley::7u4Ni1Wl\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
